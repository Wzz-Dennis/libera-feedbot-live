feed,title,long_url,short_url
ArXiv,DRAG: Director-Generator Language Modelling Framework for Non-Parallel Author Stylized Rewriting,https://arxiv.org/abs/2101.11836v1,
ArXiv,Strategic Argumentation Dialogues for Persuasion: Framework and Experiments Based on Modelling the Beliefs and Concerns of the Persuadee,https://arxiv.org/abs/2101.11870v1,
ArXiv,S++: A Fast and Deployable Secure-Computation Framework for Privacy-Preserving Neural Network Training,https://arxiv.org/abs/2101.12078v1,
ArXiv,G-MIND: An End-to-End Multimodal Imaging-Genetics Framework for Biomarker Identification and Disease Classification,https://arxiv.org/abs/2101.11656v1,
ArXiv,A Unified Framework for Feature Extraction based on Contrastive Learning,https://arxiv.org/abs/2101.11703v1,
ArXiv,Failure Prediction in Production Line Based on Federated Learning: An Empirical Study,https://arxiv.org/abs/2101.11715v1,
ArXiv,Adaptive Decision Forest: An Incremental Machine Learning Framework,https://arxiv.org/abs/2101.11828v1,
ArXiv,Interpreting and Unifying Graph Neural Networks with An Optimization Framework,https://arxiv.org/abs/2101.11859v1,
ArXiv,Potential Function-based Framework for Making the Gradients Small in Convex and Min-Max Optimization,https://arxiv.org/abs/2101.12101v1,
ArXiv,tf.data: A Machine Learning Data Processing Framework,https://arxiv.org/abs/2101.12127v1,
ArXiv,LOCCNet: a machine learning framework for distributed quantum information processing,https://arxiv.org/abs/2101.12190v1,
ArXiv,"torchdistill: A Modular, Configuration-Driven Framework for Knowledge Distillation",https://arxiv.org/abs/2011.12913v2,
