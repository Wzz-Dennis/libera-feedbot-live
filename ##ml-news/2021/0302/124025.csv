feed,title,long_url,short_url
r/ML:50+,"[R] Paper ""M6: A Chinese Multimodal Pretrainer"". Dataset contains 1900GB of images and 292GB of text. Models contain 10B parameters and 100B (Mixture-of-Experts) parameters. Images shown are text-to-image examples from the paper. Paper link is in a comment.",https://redd.it/lvv2mo,
