feed,title,long_url,short_url
r/ML:50+,"[R] mT5: A massively multilingual pre-trained text-to-text transformer that supports over 100 languages. SoTA on many cross-lingual NLP tasks. Pre-trained models, code for training and fine-tuning in comments.",https://redd.it/jgfd2d,
