feed,title,long_url,short_url
ArXiv,"Reinforcement Learning for Decision-Making and Control in Power Systems: Tutorial, Review, and Vision",https://arxiv.org/abs/2102.01168v1,
ArXiv,Reinforcement Learning with Probabilistic Boolean Network Models of Smart Grid Devices,https://arxiv.org/abs/2102.01297v1,
ArXiv,QoS-Aware Power Minimization of Distributed Many-Core Servers using Transfer Q-Learning,https://arxiv.org/abs/2102.01348v1,
ArXiv,An Abstraction-based Method to Verify Multi-Agent Deep Reinforcement-Learning Behaviours,https://arxiv.org/abs/2102.01434v1,
ArXiv,Metrics and continuity in reinforcement learning,https://arxiv.org/abs/2102.01514v1,
ArXiv,A Lyapunov Theory for Finite-Sample Guarantees of Asynchronous Q-Learning and TD-Learning Variants,https://arxiv.org/abs/2102.01567v1,
ArXiv,Approximately Solving Mean Field Games via Entropy-Regularized Deep Reinforcement Learning,https://arxiv.org/abs/2102.01585v1,
ArXiv,Towards Multi-agent Reinforcement Learning for Wireless Network Protocol Synthesis,https://arxiv.org/abs/2102.01611v1,
ArXiv,Model-Based Meta-Reinforcement Learning for Flight with Suspended Payloads,https://arxiv.org/abs/2004.11345v2,
ArXiv,Explainable Deep Reinforcement Learning for UAV Autonomous Navigation,https://arxiv.org/abs/2009.14551v2,
ArXiv,RH-Net: Improving Neural Relation Extraction via Reinforcement Learning and Hierarchical Relational Searching,https://arxiv.org/abs/2010.14255v2,
ArXiv,Self-correcting Q-Learning,https://arxiv.org/abs/2012.01100v2,
ArXiv,Unifying Cardiovascular Modelling with Deep Reinforcement Learning for Uncertainty Aware Control of Sepsis Treatment,https://arxiv.org/abs/2101.08477v2,
ArXiv,Safe Multi-Agent Reinforcement Learning via Shielding,https://arxiv.org/abs/2101.11196v2,
