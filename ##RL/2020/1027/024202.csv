feed,title,long_url,short_url
ArXiv,Stabilizing Transformer-Based Action Sequence Generation For Q-Learning,https://arxiv.org/abs/2010.12698v1,
ArXiv,Planning with Exploration: Addressing Dynamics Bottleneck in Model-based Reinforcement Learning,https://arxiv.org/abs/2010.12914v1,
ArXiv,Improving the Exploration of Deep Reinforcement Learning in Continuous Domains using Planning for Policy Search,https://arxiv.org/abs/2010.12974v1,
ArXiv,Stochastic Latent Actor-Critic: Deep Reinforcement Learning with a Latent Variable Model,https://arxiv.org/abs/1907.00953v4,
ArXiv,Reinforcement learning with world model,https://arxiv.org/abs/1908.11494v4,
ArXiv,Multi-task Batch Reinforcement Learning with Metric Learning,https://arxiv.org/abs/1909.11373v6,
ArXiv,Preference-based Reinforcement Learning with Finite-Time Guarantees,https://arxiv.org/abs/2006.08910v2,
ArXiv,Generating Adjacency-Constrained Subgoals in Hierarchical Reinforcement Learning,https://arxiv.org/abs/2006.11485v2,
ArXiv,Model-based Reinforcement Learning for Semi-Markov Decision Processes with Neural ODEs,https://arxiv.org/abs/2006.16210v2,
ArXiv,Maximum Mutation Reinforcement Learning for Scalable Control,https://arxiv.org/abs/2007.13690v3,
ArXiv,Fast Adaptive Task Offloading in Edge Computing based on Meta Reinforcement Learning,https://arxiv.org/abs/2008.02033v5,
ArXiv,Deep Reinforcement Learning for Contact-Rich Skills Using Compliant Movement Primitives,https://arxiv.org/abs/2008.13223v2,
ArXiv,Neurosymbolic Reinforcement Learning with Formally Verified Exploration,https://arxiv.org/abs/2009.12612v2,
ArXiv,How to Stop Epidemics: Controlling Graph Dynamics with Reinforcement Learning and Graph Neural Networks,https://arxiv.org/abs/2010.05313v2,
ArXiv,High Acceleration Reinforcement Learning for Real-World Juggling with Binary Rewards,https://arxiv.org/abs/2010.13483v1,
