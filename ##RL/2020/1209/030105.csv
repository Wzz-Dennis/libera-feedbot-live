feed,title,long_url,short_url
ArXiv,Battery Model Calibration with Deep Reinforcement Learning,https://arxiv.org/abs/2012.04010v1,
ArXiv,The Architectural Implications of Distributed Reinforcement Learning on CPU-GPU Systems,https://arxiv.org/abs/2012.04210v1,
ArXiv,NavRep: Unsupervised Representations for Reinforcement Learning of Robot Navigation in Dynamic Human Environments,https://arxiv.org/abs/2012.04406v1,
ArXiv,Combining reinforcement learning with lin-kernighan-helsgaun algorithm for the traveling salesman problem,https://arxiv.org/abs/2012.04461v1,
ArXiv,"Models, Pixels, and Rewards: Evaluating Design Trade-offs in Visual Model-Based Reinforcement Learning",https://arxiv.org/abs/2012.04603v1,
ArXiv,Deep Multi-Agent Reinforcement Learning for Decentralized Continuous Cooperative Control,https://arxiv.org/abs/2003.06709v4,
ArXiv,Exploration by Maximizing R\'enyi Entropy for Zero-Shot Meta RL,https://arxiv.org/abs/2006.06193v2,
ArXiv,Value-Decomposition Multi-Agent Actor-Critics,https://arxiv.org/abs/2007.12306v3,
ArXiv,Graph-based Reinforcement Learning for Active Learning in Real Time: An Application in Modeling River Networks,https://arxiv.org/abs/2010.14000v2,
ArXiv,One Solution is Not All You Need: Few-Shot Extrapolation via Structured MaxEnt RL,https://arxiv.org/abs/2010.14484v2,
