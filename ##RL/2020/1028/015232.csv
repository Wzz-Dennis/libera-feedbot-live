feed,title,long_url,short_url
ArXiv,VisualHints: A Visual-Lingual Environment for Multimodal Reinforcement Learning,https://arxiv.org/abs/2010.13839v1,
ArXiv,MELD: Meta-Reinforcement Learning from Images via Latent State Models,https://arxiv.org/abs/2010.13957v1,
ArXiv,Graph-based Reinforcement Learning for Active Learning in Real Time: An Application in Modeling River Networks,https://arxiv.org/abs/2010.14000v1,
ArXiv,Hamilton-Jacobi Deep Q-Learning for Deterministic Continuous-Time Systems with Lipschitz Continuous Controls,https://arxiv.org/abs/2010.14087v1,
ArXiv,Energy Consumption and Battery Aging Minimization Using a Q-learning Strategy for a Battery/Ultracapacitor Electric Vehicle,https://arxiv.org/abs/2010.14115v1,
ArXiv,Learning Financial Asset-Specific Trading Rules via Deep Reinforcement Learning,https://arxiv.org/abs/2010.14194v1,
ArXiv,Improving Reinforcement Learning for Neural Relation Extraction with Hierarchical Memory Extractor,https://arxiv.org/abs/2010.14255v1,
ArXiv,Behavior Priors for Efficient Reinforcement Learning,https://arxiv.org/abs/2010.14274v1,
ArXiv,Can Reinforcement Learning for Continuous Control Generalize Across Physics Engines?,https://arxiv.org/abs/2010.14444v1,
ArXiv,One Solution is Not All You Need: Few-Shot Extrapolation via Structured MaxEnt RL,https://arxiv.org/abs/2010.14484v1,
ArXiv,$\gamma$-Models: Generative Temporal Difference Learning for Infinite-Horizon Prediction,https://arxiv.org/abs/2010.14496v1,
ArXiv,Implicit Under-Parameterization Inhibits Data-Efficient Deep Reinforcement Learning,https://arxiv.org/abs/2010.14498v1,
ArXiv,COG: Connecting New Skills to Past Experience with Offline Reinforcement Learning,https://arxiv.org/abs/2010.14500v1,
ArXiv,Guided Meta-Policy Search,https://arxiv.org/abs/1904.00956v2,
ArXiv,Multi-Vehicle Routing Problems with Soft Time Windows: A Multi-Agent Reinforcement Learning Approach,https://arxiv.org/abs/2002.05513v2,
ArXiv,Multi-Agent Reinforcement Learning as a Computational Tool for Language Evolution Research: Historical Context and Future Challenges,https://arxiv.org/abs/2002.08878v2,
ArXiv,OPAL: Offline Primitive Discovery for Accelerating Offline Reinforcement Learning,https://arxiv.org/abs/2010.13611v2,
