feed,title,long_url,short_url
PwC:Trending,Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention,https://paperswithcode.com/paper/transformers-are-rnns-fast-autoregressive,https://j.mp/3eZ0Zf1
PwC:Trending,Efficient Attention: Attention with Linear Complexities,https://paperswithcode.com/paper/factorized-attention-self-attention-with,https://j.mp/2ZdshJj
