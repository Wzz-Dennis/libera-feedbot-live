feed,title,long_url,short_url
ArXiv,Learning from humans: combining imitation and deep reinforcement learning to accomplish human-level performance on a virtual foraging task,https://arxiv.org/abs/2203.06250v1,
ArXiv,Stable and Efficient Shapley Value-Based Reward Reallocation for Multi-Agent Reinforcement Learning of Autonomous Vehicles,https://arxiv.org/abs/2203.06333v1,
ArXiv,The Health Gym: Synthetic Health-Related Datasets for the Development of Reinforcement Learning Algorithms,https://arxiv.org/abs/2203.06369v1,
ArXiv,Concentration Network for Reinforcement Learning of Large-Scale Multi-Agent Systems,https://arxiv.org/abs/2203.06416v1,
ArXiv,A Deep Reinforcement Learning Environment for Particle Robot Navigation and Object Manipulation,https://arxiv.org/abs/2203.06464v1,
ArXiv,DARA: Dynamics-Aware Reward Augmentation in Offline Reinforcement Learning,https://arxiv.org/abs/2203.06662v1,
ArXiv,Survey on reinforcement learning for language processing,https://arxiv.org/abs/2104.05565v2,
ArXiv,PowerGym: A Reinforcement Learning Environment for Volt-Var Control in Power Distribution Systems,https://arxiv.org/abs/2109.03970v3,
ArXiv,Soft Actor-Critic With Integer Actions,https://arxiv.org/abs/2109.08512v2,
ArXiv,A Multi-Agent Deep Reinforcement Learning Coordination Framework for Connected and Automated Vehicles at Merging Roadways,https://arxiv.org/abs/2109.11672v2,
ArXiv,Actor-critic is implicitly biased towards high entropy optimal policies,https://arxiv.org/abs/2110.11280v2,
ArXiv,A Framework for Transforming Specifications in Reinforcement Learning,https://arxiv.org/abs/2111.00272v2,
ArXiv,Can Wikipedia Help Offline Reinforcement Learning?,https://arxiv.org/abs/2201.12122v2,
ArXiv,GraspARL: Dynamic Grasping via Adversarial Reinforcement Learning,https://arxiv.org/abs/2203.02119v2,
ArXiv,The Efficacy of Pessimism in Asynchronous Q-Learning,https://arxiv.org/abs/2203.07368v1,
ArXiv,Calibration of Derivative Pricing Models: a Multi-Agent Reinforcement Learning Perspective,https://arxiv.org/abs/2203.06865v1,
