feed,title,long_url,short_url
ArXiv,Multi-fidelity reinforcement learning framework for shape optimization,https://arxiv.org/abs/2202.11170v1,
ArXiv,Deep Reinforcement Learning: Opportunities and Challenges,https://arxiv.org/abs/2202.11296v1,
ArXiv,Reinforcement Learning from Demonstrations by Novel Interactive Expert and Application to Automatic Berthing Control Systems for Unmanned Surface Vessel,https://arxiv.org/abs/2202.11325v1,
ArXiv,Using Deep Reinforcement Learning with Automatic Curriculum earning for Mapless Navigation in Intralogistics,https://arxiv.org/abs/2202.11512v1,
ArXiv,A Comparative Study of Deep Reinforcement Learning-based Transferable Energy Management Strategies for Hybrid Electric Vehicles,https://arxiv.org/abs/2202.11514v1,
ArXiv,Pessimistic Bootstrapping for Uncertainty-Driven Offline Reinforcement Learning,https://arxiv.org/abs/2202.11566v1,
ArXiv,Globally Convergent Policy Search over Dynamic Filters for Output Estimation,https://arxiv.org/abs/2202.11659v1,
ArXiv,Deep Reinforcement Learning based Joint Active and Passive Beamforming Design for RIS-Assisted MISO Systems,https://arxiv.org/abs/2202.11702v1,
ArXiv,Multi-Agent Reinforcement Learning for Joint Cooperative Spectrum Sensing and Channel Access in Cognitive UAV Networks,https://arxiv.org/abs/2103.08181v3,
ArXiv,A Deep Reinforcement Learning Approach for the Meal Delivery Problem,https://arxiv.org/abs/2104.12000v2,
ArXiv,Analysis of a Target-Based Actor-Critic Algorithm with Linear Function Approximation,https://arxiv.org/abs/2106.07472v2,
ArXiv,A review of mobile robot motion planning methods: from classical motion planning workflows to reinforcement learning-based architectures,https://arxiv.org/abs/2108.13619v4,
