feed,title,long_url,short_url
ArXiv,Attaining Interpretability in Reinforcement Learning via Hierarchical Primitive Composition,https://arxiv.org/abs/2110.01833v1,
ArXiv,Deep reinforcement learning for guidewire navigation in coronary artery phantom,https://arxiv.org/abs/2110.01840v1,
ArXiv,DeepEdge: A Deep Reinforcement Learning based Task Orchestrator for Edge Computing,https://arxiv.org/abs/2110.01863v1,
ArXiv,Improved Reinforcement Learning Coordinated Control of a Mobile Manipulator using Joint Clamping,https://arxiv.org/abs/2110.01926v1,
ArXiv,Dropout Q-Functions for Doubly Efficient Reinforcement Learning,https://arxiv.org/abs/2110.02034v1,
ArXiv,CARL: A Benchmark for Contextual and Adaptive Reinforcement Learning,https://arxiv.org/abs/2110.02102v1,
ArXiv,NeurWIN: Neural Whittle Index Network For Restless Bandits Via Deep RL,https://arxiv.org/abs/2110.02128v1,
ArXiv,A study of first-passage time minimization via Q-learning in heated gridworlds,https://arxiv.org/abs/2110.02129v1,
ArXiv,NaRLE: Natural Language Models using Reinforcement Learning with Emotion Feedback,https://arxiv.org/abs/2110.02148v1,
ArXiv,Deep Reinforcement Learning for Decentralized Multi-Robot Exploration with Macro Actions,https://arxiv.org/abs/2110.02181v1,
ArXiv,Safe Model-Based Reinforcement Learning for Systems with Parametric Uncertainties,https://arxiv.org/abs/2007.12666v5,
ArXiv,Reinforcement Learning Based Temporal Logic Control with Maximum Probabilistic Satisfaction,https://arxiv.org/abs/2010.06797v5,
ArXiv,MAP Propagation Algorithm: Faster Learning with a Team of Reinforcement Learning Agents,https://arxiv.org/abs/2010.07893v2,
ArXiv,Modular Deep Reinforcement Learning for Continuous Motion Planning with Temporal Logic,https://arxiv.org/abs/2102.12855v4,
ArXiv,Model-aided Deep Reinforcement Learning for Sample-efficient UAV Trajectory Design in IoT Networks,https://arxiv.org/abs/2104.10403v3,
ArXiv,Optimal Power Allocation for Rate Splitting Communications with Deep Reinforcement Learning,https://arxiv.org/abs/2107.00238v2,
ArXiv,Cautious Actor-Critic,https://arxiv.org/abs/2107.05217v2,
ArXiv,Cautious Policy Programming: Exploiting KL Regularization in Monotonic Policy Improvement for Reinforcement Learning,https://arxiv.org/abs/2107.05798v2,
ArXiv,Geometric Value Iteration: Dynamic Error-Aware KL Regularization for Reinforcement Learning,https://arxiv.org/abs/2107.07659v2,
ArXiv,End-to-End Urban Driving by Imitating a Reinforcement Learning Coach,https://arxiv.org/abs/2108.08265v3,
ArXiv,Temporal Shift Reinforcement Learning,https://arxiv.org/abs/2109.02145v2,
ArXiv,Uncertainty-Based Offline Reinforcement Learning with Diversified Q-Ensemble,https://arxiv.org/abs/2110.01548v2,
ArXiv,A Modified Q-Learning Algorithm for Rate-Profiling of Polarization Adjusted Convolutional (PAC) Codes,https://arxiv.org/abs/2110.01563v2,
ArXiv,Reinforcement Learning with Real-time Docking of 3D Structures to Cover Chemical Space: Mining for Potent SARS-CoV-2 Main Protease Inhibitors,https://arxiv.org/abs/2110.01806v1,
