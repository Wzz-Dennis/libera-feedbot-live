feed,title,long_url,short_url
ArXiv,Inverse Design of Grating Couplers Using the Policy Gradient Method from Reinforcement Learning,https://arxiv.org/abs/2107.00088v1,
ArXiv,Reinforcement Learning for Abstractive Question Summarization with Question-aware Semantic Rewards,https://arxiv.org/abs/2107.00176v1,
ArXiv,Optimal Power Allocation for Rate Splitting Communications with Deep Reinforcement Learning,https://arxiv.org/abs/2107.00238v1,
ArXiv,MHER: Model-based Hindsight Experience Replay,https://arxiv.org/abs/2107.00306v1,
ArXiv,Model Mediated Teleoperation with a Hand-Arm Exoskeleton in Long Time Delays Using Reinforcement Learning,https://arxiv.org/abs/2107.00359v1,
ArXiv,Adaptive Stochastic ADMM for Decentralized Reinforcement Learning in Edge Industrial IoT,https://arxiv.org/abs/2107.00481v1,
ArXiv,Goal-Conditioned Reinforcement Learning with Imagined Subgoals,https://arxiv.org/abs/2107.00541v1,
ArXiv,Offline-to-Online Reinforcement Learning via Balanced Replay and Pessimistic Q-Ensemble,https://arxiv.org/abs/2107.00591v1,
ArXiv,Stabilizing Deep Q-Learning with ConvNets and Vision Transformers under Data Augmentation,https://arxiv.org/abs/2107.00644v1,
ArXiv,Goal-Auxiliary Actor-Critic for 6D Robotic Grasping with Point Clouds,https://arxiv.org/abs/2010.00824v4,
ArXiv,Temporal Difference Uncertainties as a Signal for Exploration,https://arxiv.org/abs/2010.02255v2,
ArXiv,Information-theoretic Task Selection for Meta-Reinforcement Learning,https://arxiv.org/abs/2011.01054v2,
ArXiv,Decoupled Exploration and Exploitation Policies for Sample-Efficient Reinforcement Learning,https://arxiv.org/abs/2101.09458v2,
ArXiv,Rethinking the Implementation Tricks and Monotonicity Constraint in Cooperative Multi-Agent Reinforcement Learning,https://arxiv.org/abs/2102.03479v12,
ArXiv,Gym-$\mu$RTS: Toward Affordable Full Game Real-time Strategy Games Research with Deep Reinforcement Learning,https://arxiv.org/abs/2105.13807v2,
ArXiv,Reinforcement Learning for Physical Layer Communications,https://arxiv.org/abs/2106.11595v2,
ArXiv,Noisy-MAPPO: Noisy Advantage Values for Cooperative Multi-agent Actor-Critic methods,https://arxiv.org/abs/2106.14334v2,
ArXiv,Importance Sampling based Exploration in Q Learning,https://arxiv.org/abs/2107.00602v1,
