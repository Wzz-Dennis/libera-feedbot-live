feed,title,long_url,short_url
ArXiv,Balancing Value Underestimation and Overestimationwith Realistic Actor-Critic,https://arxiv.org/abs/2110.09712v1,
ArXiv,On Reward-Free RL with Kernel and Neural Function Approximations: Single-Agent MDP and Markov Game,https://arxiv.org/abs/2110.09771v1,
ArXiv,Aesthetic Photo Collage with Deep Reinforcement Learning,https://arxiv.org/abs/2110.09775v1,
ArXiv,Offline Reinforcement Learning with Value-based Episodic Memory,https://arxiv.org/abs/2110.09796v1,
ArXiv,State-based Episodic Memory for Multi-Agent Reinforcement Learning,https://arxiv.org/abs/2110.09817v1,
ArXiv,Neural Network Compatible Off-Policy Natural Actor-Critic Algorithm,https://arxiv.org/abs/2110.10017v1,
ArXiv,"CORA: Benchmarks, Baselines, and Metrics as a Platform for Continual Reinforcement Learning Agents",https://arxiv.org/abs/2110.10067v1,
ArXiv,Locally Differentially Private Reinforcement Learning for Linear Mixture Markov Decision Processes,https://arxiv.org/abs/2110.10133v1,
ArXiv,Towards Hierarchical Task Decomposition using Deep Reinforcement Learning for Pick and Place Subtasks,https://arxiv.org/abs/2102.04022v3,
ArXiv,On Lottery Tickets and Minimal Task Representations in Deep Reinforcement Learning,https://arxiv.org/abs/2105.01648v3,
ArXiv,Improved Exploring Starts by Kernel Density Estimation-Based State-Space Coverage Acceleration in Reinforcement Learning,https://arxiv.org/abs/2105.08990v2,
ArXiv,Robust Model-based Reinforcement Learning for Autonomous Greenhouse Control,https://arxiv.org/abs/2108.11645v2,
ArXiv,Pythia: A Customizable Hardware Prefetching Framework Using Online Reinforcement Learning,https://arxiv.org/abs/2109.12021v2,
ArXiv,Online Target Q-learning with Reverse Experience Replay: Efficiently finding the Optimal Policy for Linear MDPs,https://arxiv.org/abs/2110.08440v2,
ArXiv,Improving Robustness of Reinforcement Learning for Power System Control with Adversarial Training,https://arxiv.org/abs/2110.08956v2,
ArXiv,Identifying optimally cost-effective dynamic treatment regimes with a Q-learning approach,https://arxiv.org/abs/2107.03441v3,
