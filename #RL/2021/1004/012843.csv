feed,title,long_url,short_url
ArXiv,Trajectory Planning with Deep Reinforcement Learning in High-Level Action Spaces,https://arxiv.org/abs/2110.00044v1,
ArXiv,Decentralized Graph-Based Multi-Agent Reinforcement Learning Using Reward Machines,https://arxiv.org/abs/2110.00096v1,
ArXiv,Offline Reinforcement Learning with Reverse Model-based Imagination,https://arxiv.org/abs/2110.00188v1,
ArXiv,DNN-Opt: An RL Inspired Optimization for Analog Circuit Sizing using Deep Neural Networks,https://arxiv.org/abs/2110.00211v1,
ArXiv,Safety aware model-based reinforcement learning for optimal control of a class of output-feedback nonlinear systems,https://arxiv.org/abs/2110.00271v1,
ArXiv,Divergence-Regularized Multi-Agent Actor-Critic,https://arxiv.org/abs/2110.00304v1,
ArXiv,Cellular traffic offloading via Opportunistic Networking with Reinforcement Learning,https://arxiv.org/abs/2110.00397v1,
ArXiv,Dynamic CU-DU Selection for Resource Allocation in O-RAN Using Actor-Critic Learning,https://arxiv.org/abs/2110.00492v1,
ArXiv,A Cram\'er Distance perspective on Non-crossing Quantile Regression in Distributional Reinforcement Learning,https://arxiv.org/abs/2110.00535v1,
ArXiv,Mean-Field Controls with Q-learning for Cooperative MARL: Convergence and Complexity Analysis,https://arxiv.org/abs/2002.04131v6,
ArXiv,Solving the scalarization issues of Advantage-based Reinforcement Learning Algorithms,https://arxiv.org/abs/2004.04120v4,
ArXiv,Revisiting the Monotonicity Constraint in Cooperative Multi-Agent Reinforcement Learning,https://arxiv.org/abs/2102.03479v15,
ArXiv,Inverse Reinforcement Learning: A Control Lyapunov Approach,https://arxiv.org/abs/2104.04483v2,
ArXiv,Policy Perturbation via Noisy Advantage Values for Cooperative Multi-agent Actor-Critic methods,https://arxiv.org/abs/2106.14334v11,
