feed,title,long_url,short_url
ArXiv,Learning When and What to Ask: a Hierarchical Reinforcement Learning Framework,https://arxiv.org/abs/2110.08258v1,
ArXiv,Dynamic probabilistic logic models for effective abstractions in RL,https://arxiv.org/abs/2110.08318v1,
ArXiv,Online Target Q-learning with Reverse Experience Replay: Efficiently finding the Optimal Policy for Linear MDPs,https://arxiv.org/abs/2110.08440v1,
ArXiv,Deep Reinforcement Learning for Practical Phase Shift Optimization in RIS-aided MISO URLLC Systems,https://arxiv.org/abs/2110.08513v1,
ArXiv,Neural Network Pruning Through Constrained Reinforcement Learning,https://arxiv.org/abs/2110.08558v1,
ArXiv,Local Advantage Actor-Critic for Robust Multi-Agent Deep Reinforcement Learning,https://arxiv.org/abs/2110.08642v1,
ArXiv,Improving reinforcement learning algorithms: towards optimal learning rate policies,https://arxiv.org/abs/1911.02319v5,
ArXiv,Upper Confidence Primal-Dual Reinforcement Learning for CMDP with Adversarial Loss,https://arxiv.org/abs/2003.00660v3,
ArXiv,Macro-Action-Based Deep Multi-Agent Reinforcement Learning,https://arxiv.org/abs/2004.08646v2,
ArXiv,Efficient Connected and Automated Driving Systemwith Multi-agent Graph Reinforcement Learning,https://arxiv.org/abs/2007.02794v4,
ArXiv,Alchemy: A structured task distribution for meta-reinforcement learning,https://arxiv.org/abs/2102.02926v2,
ArXiv,Reinforcement Learning for Ridesharing: A Survey,https://arxiv.org/abs/2105.01099v2,
ArXiv,Sample-Efficient Reinforcement Learning Is Feasible for Linearly Realizable MDPs with Limited Revisiting,https://arxiv.org/abs/2105.08024v2,
ArXiv,Ensemble Quantile Networks: Uncertainty-Aware Reinforcement Learning with Applications in Autonomous Driving,https://arxiv.org/abs/2105.10266v2,
ArXiv,The Role of Pretrained Representations for the OOD Generalization of RL Agents,https://arxiv.org/abs/2107.05686v2,
ArXiv,Terminal Adaptive Guidance for Autonomous Hypersonic Strike Weapons via Reinforcement Learning,https://arxiv.org/abs/2110.00634v2,
ArXiv,Improving Robustness of Reinforcement Learning for Power System Control with Adversarial Training,https://arxiv.org/abs/2110.08956v1,
ArXiv,A Q-Learning-based Approach for Distributed Beam Scheduling in mmWave Networks,https://arxiv.org/abs/2110.08704v1,
ArXiv,"Damped Anderson Mixing for Deep Reinforcement Learning: Acceleration, Convergence, and Stabilization",https://arxiv.org/abs/2110.08896v1,
ArXiv,An actor-critic algorithm with deep double recurrent agents to solve the job shop scheduling problem,https://arxiv.org/abs/2110.09076v1,
ArXiv,Towards Instance-Optimal Offline Reinforcement Learning with Pessimism,https://arxiv.org/abs/2110.08695v1,
ArXiv,Provable Hierarchy-Based Meta-Reinforcement Learning,https://arxiv.org/abs/2110.09507v1,
