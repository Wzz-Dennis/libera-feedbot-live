feed,title,long_url,short_url
ArXiv,Reinforcement Learning for Emotional Text-to-Speech Synthesis with Improved Emotion Discriminability,https://arxiv.org/abs/2104.01408v1,
ArXiv,Deep Reinforcement Learning Powered IRS-Assisted Downlink NOMA,https://arxiv.org/abs/2104.01414v1,
ArXiv,A Dynamics Perspective of Pursuit-Evasion Games of Intelligent Agents with the Ability to Learn,https://arxiv.org/abs/2104.01445v1,
ArXiv,Influencing Reinforcement Learning through Natural Language Guidance,https://arxiv.org/abs/2104.01506v1,
ArXiv,Reinforcement Learning for Minimizing Age of Information in Real-time Internet of Things Systems with Realistic Physical Dynamics,https://arxiv.org/abs/2104.01527v1,
ArXiv,Reinforcement Learning with Temporal Logic Constraints for Partially-Observable Markov Decision Processes,https://arxiv.org/abs/2104.01612v1,
ArXiv,Efficient Transformers in Reinforcement Learning using Actor-Learner Distillation,https://arxiv.org/abs/2104.01655v1,
ArXiv,A Dual-Critic Reinforcement Learning Framework for Frame-level Bit Allocation in HEVC/H.265,https://arxiv.org/abs/2104.01735v1,
ArXiv,UDO: Universal Database Optimization using Reinforcement Learning,https://arxiv.org/abs/2104.01744v1,
ArXiv,Asymptotics of Reinforcement Learning with Neural Networks,https://arxiv.org/abs/1911.07304v4,
ArXiv,Lucid Dreaming for Experience Replay: Refreshing Past States with the Current Policy,https://arxiv.org/abs/2009.13736v3,
ArXiv,Direct Expected Quadratic Utility Maximization for Mean-Variance Controlled Reinforcement Learning,https://arxiv.org/abs/2010.01404v2,
ArXiv,Improving Actor-Critic Reinforcement Learning via Hamiltonian Policy,https://arxiv.org/abs/2103.12020v2,
