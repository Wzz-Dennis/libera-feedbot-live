feed,title,long_url,short_url
ArXiv,RAPID-RL: A Reconfigurable Architecture with Preemptive-Exits for Efficient Deep-Reinforcement Learning,https://arxiv.org/abs/2109.08231v1,
ArXiv,Reinforcement Learning on Encrypted Data,https://arxiv.org/abs/2109.08236v1,
ArXiv,Accelerating Offline Reinforcement Learning Application in Real-Time Bidding and Recommendation: Potential Use of Simulation,https://arxiv.org/abs/2109.08331v1,
ArXiv,Coordinated Random Access for Industrial IoT With Correlated Traffic By Reinforcement-Learning,https://arxiv.org/abs/2109.08389v1,
ArXiv,Carl-Lead: Lidar-based End-to-End Autonomous Driving with Contrastive Deep Reinforcement Learning,https://arxiv.org/abs/2109.08473v1,
ArXiv,Soft Actor-Critic With Integer Actions,https://arxiv.org/abs/2109.08512v1,
ArXiv,Decentralized Global Connectivity Maintenance for Multi-Robot Navigation: A Reinforcement Learning Approach,https://arxiv.org/abs/2109.08536v1,
ArXiv,Smoothed functional-based gradient algorithms for off-policy reinforcement learning: A non-asymptotic viewpoint,https://arxiv.org/abs/2101.02137v5,
ArXiv,AdaptSky: A DRL Based Resource Allocation Framework in NOMA-UAV Networks,https://arxiv.org/abs/2107.01004v3,
ArXiv,Hepatocellular Carcinoma Segmentation from Digital Subtraction Angiography Videos using Learnable Temporal Difference,https://arxiv.org/abs/2107.04306v3,
ArXiv,Path Planning for Cellular-Connected UAV: A DRL Solution with Quantum-Inspired Experience Replay,https://arxiv.org/abs/2108.13184v2,
