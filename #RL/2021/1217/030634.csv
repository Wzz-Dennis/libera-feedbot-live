feed,title,long_url,short_url
ArXiv,Feature-Attending Recurrent Modules for Generalization in Reinforcement Learning,https://arxiv.org/abs/2112.08369v1,
ArXiv,CONQRR: Conversational Query Rewriting for Retrieval with Reinforcement Learning,https://arxiv.org/abs/2112.08558v1,
ArXiv,Goal-Directed Story Generation: Augmenting Generative Language Models with Reinforcement Learning,https://arxiv.org/abs/2112.08593v1,
ArXiv,Learning to Share in Multi-Agent Reinforcement Learning,https://arxiv.org/abs/2112.08702v1,
ArXiv,Unsupervised Reinforcement Learning in Multiple Environments,https://arxiv.org/abs/2112.08746v1,
ArXiv,Inherently Explainable Reinforcement Learning in Natural Language,https://arxiv.org/abs/2112.08907v1,
ArXiv,Centralizing State-Values in Dueling Networks for Multi-Robot Reinforcement Learning Mapless Navigation,https://arxiv.org/abs/2112.09012v1,
ArXiv,Deep Reinforcement Learning Policies Learn Shared Adversarial Features Across MDPs,https://arxiv.org/abs/2112.09025v1,
ArXiv,A Generalized Minimax Q-learning Algorithm for Two-Player Zero-Sum Stochastic Games,https://arxiv.org/abs/1906.06659v5,
ArXiv,On the Estimation Bias in Double Q-Learning,https://arxiv.org/abs/2109.14419v2,
ArXiv,Explanation-Aware Experience Replay in Rule-Dense Environments,https://arxiv.org/abs/2109.14711v2,
ArXiv,Policy Search for Model Predictive Control with Application to Agile Drone Flight,https://arxiv.org/abs/2112.03850v2,
