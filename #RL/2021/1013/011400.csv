feed,title,long_url,short_url
ArXiv,Urban traffic dynamic rerouting framework: A DRL-based model with fog-cloud architecture,https://arxiv.org/abs/2110.05532v1,
ArXiv,Addressing crash-imminent situations caused by human driven vehicle errors in a mixed traffic stream: a model-based reinforcement learning approach for CAV,https://arxiv.org/abs/2110.05556v1,
ArXiv,Scalable Traffic Signal Controls using Fog-Cloud Based Multiagent Reinforcement Learning,https://arxiv.org/abs/2110.05564v1,
ArXiv,Learning to Coordinate in Multi-Agent Systems: A Coordinated Actor-Critic Algorithm and Finite-Time Guarantees,https://arxiv.org/abs/2110.05597v1,
ArXiv,Provably Efficient Reinforcement Learning in Decentralized General-Sum Markov Games,https://arxiv.org/abs/2110.05682v1,
ArXiv,Decentralized Cooperative Multi-Agent Reinforcement Learning with Exploration,https://arxiv.org/abs/2110.05707v1,
ArXiv,Temporal Abstraction in Reinforcement Learning with the Successor Representation,https://arxiv.org/abs/2110.05740v1,
ArXiv,Directionality Reinforcement Learning to Operate Multi-Agent System without Communication,https://arxiv.org/abs/2110.05773v1,
ArXiv,Fast Block Linear System Solver Using Q-Learning Schduling for Unified Dynamic Power System Simulations,https://arxiv.org/abs/2110.05843v1,
ArXiv,Multi-condition multi-objective optimization using deep reinforcement learning,https://arxiv.org/abs/2110.05945v1,
ArXiv,Offline Reinforcement Learning with Implicit Q-Learning,https://arxiv.org/abs/2110.06169v1,
ArXiv,Generative Temporal Difference Learning for Infinite-Horizon Prediction,https://arxiv.org/abs/2010.14496v3,
ArXiv,TAAC: Temporally Abstract Actor-Critic for Continuous Control,https://arxiv.org/abs/2104.06521v3,
ArXiv,SoCRATES: System-on-Chip Resource Adaptive Scheduling using Deep Reinforcement Learning,https://arxiv.org/abs/2104.14354v3,
ArXiv,Policy Smoothing for Provably Robust Reinforcement Learning,https://arxiv.org/abs/2106.11420v2,
